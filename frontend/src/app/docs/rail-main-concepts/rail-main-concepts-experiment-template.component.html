<app-base-doc>
    <h1>Experiment Template</h1>

    <h2>What is Experiment template</h2>
    <p>
        Experiment template is a combination of runtime environment, software dependencies and code.
    </p>
    <ul>
        <li><b>Runtime environment</b> is a specification of the environment in which the experiment is executed. In
            RAIL, it is a specific Docker image.</li>
        <li><b>Software dependencies</b> are the software packages that are required to execute the experiment.
            Currently, <code>requirements.txt</code> file with Python dependencies is supported.</li>
        <li><b>Code</b> is the code that is executed in the experiment.</li>
    </ul>

    <img src="assets/docs/images/rail-concepts-template.png" alt="Rail concepts: Experiment template"
    class="doc-illustration-figure">

    <h1>Examples of experiment templates</h1>
    Experiment Templates are versatile and can be used for various purposes. Here are some examples of Experiment
    Templates.

    <h2>Machine translation</h2>
    <ul>
        <li>
            Description: A machine translation pipeline that can use any compatible HuggingFace translation model and
            translate any HuggingFace dataset containing texts. Users can select <b>translate_from</b> and
            <b>translate_to</b>
            languages. It saves translated texts to a CSV file.
        </li>
        <li>
            Runtime environment: Docker image python:3.11
        </li>
        <li>
            Software dependencies: Python libraries listed in requirements.txt file
        </li>
        <li>
            Code: Python code that uses HuggingFace transformers and datasets libraries
        </li>
    </ul>

    <h2>Text summarization</h2>
    <ul>
        <li>
            Description: A text summarization pipeline that can use a compatible HuggingFace summarization model
            (including large language models) and summarize any texts in a HuggingFace dataset. Users can specify
            <b>max_length</b> of the summarization. It saves summarized texts to a CSV file.
        </li>
        <li>
            Runtime environment: Docker image python:3.12
        </li>
        <li>
            Software dependencies: Python libraries listed in requirements.txt file
        </li>
        <li>
            Code: Python code that uses HuggingFace transformers and datasets libraries
        </li>
    </ul>

    <h2>Fine-tune a text sentiment classifier</h2>
    <ul>
        <li>
            Description: Fine-tunes a selected compatible HuggingFace text sentiment classification model on a selected
            HuggingFace dataset. Saves fine-tuned model to an “output/model” directory.
        </li>
        <li>
            Runtime environment: Docker image python:3.11
        </li>
        <li>
            Software dependencies: Python libraries listed in requirements.txt file
        </li>
        <li>
            Code: Python code that uses PyTorch, HuggingFace’s transformers and datasets libraries. It downloads models
            from the author's server, dataset specified by the user and performs semantic segmentation.
        </li>
    </ul>

    <h2>Semantic image segmentation</h2>
    <ul>
        <li>
            Description: Uses a fixed model (specified in the code by the author of the template) to perform semantic
            segmentation of images in a HuggingFace or Zenodo dataset. Resulting segmentation masks are saved to a
            separate folder as .png images.
        </li>
        <li>
            Runtime environment: Docker image python:3.9
        </li>
        <li>
            Software dependencies: Python libraries listed in requirements.txt file
        </li>
        <li>
            Code: Python code that uses PyTorch, HuggingFace’s transformers and datasets libraries. It downloads models
            from the author's server, dataset specified by the user and performs semantic segmentation.
        </li>
    </ul>

    <!-- multiple examples in tabs -->
    <!-- <mat-tab-group style="width: 100%" mat-stretch-tabs="false" mat-align-tabs="start">
        <mat-tab label="Machine translation">
            <ul>
                <li>
                    Description: A machine translation pipeline that can use any compatible HuggingFace translation model and
                    translate any HuggingFace dataset containing texts. Users can select <b>translate_from</b> and <b>translate_to</b>
                    languages. It saves translated texts to a CSV file.
                </li>
                <li>
                    Runtime environment: Docker image python:3.11
                </li>
                <li>
                    Software dependencies: Python libraries listed in requirements.txt file
                </li>
                <li>
                    Code: Python code that uses HuggingFace transformers and datasets libraries
                </li>
            </ul>
        </mat-tab>
        <mat-tab label="Text summarization">
            <ul>
                <li>
                    Description: A text summarization pipeline that can use a compatible HuggingFace summarization model (including large language models) and summarize any texts in a HuggingFace dataset. Users can specify <b>max_length</b> of the summarization. It saves summarized texts to a CSV file.
                </li>
                <li>
                    Runtime environment: Docker image python:3.12
                </li>
                <li>
                    Software dependencies: Python libraries listed in requirements.txt file
                </li>
                <li>
                    Code: Python code that uses HuggingFace transformers and datasets libraries
                </li>
            </ul>
        </mat-tab>
        <mat-tab label="Fine-tune sentiment classifier">
            <ul>
                <li>
                    Description: Fine-tunes a selected compatible HuggingFace text sentiment classification model on a selected HuggingFace dataset. Saves fine-tuned model to an “output/model” directory.
                </li>
                <li>
                    Runtime environment: Docker image python:3.11
                </li>
                <li>
                    Software dependencies: Python libraries listed in requirements.txt file
                </li>
                <li>
                    Code: Python code that uses PyTorch, HuggingFace’s transformers and datasets libraries. It downloads models from the author's server, dataset specified by the user and performs semantic segmentation.
                </li>
            </ul>
        </mat-tab>
        <mat-tab label="Semantic image segmentation">
            <ul>
                <li>
                    Description: Uses a fixed model (specified in the code by the author of the template) to perform semantic segmentation of images in a HuggingFace or Zenodo dataset. Resulting segmentation masks are saved to a separate folder as .png images.
                </li>
                <li>
                    Runtime environment: Docker image python:3.9
                </li>
                <li>
                    Software dependencies: Python libraries listed in requirements.txt file
                </li>
                <li>
                    Code: Python code that uses PyTorch, HuggingFace’s transformers and datasets libraries. It downloads models from the author's server, dataset specified by the user and performs semantic segmentation.
                </li>
            </ul>
        </mat-tab>
    </mat-tab-group> -->

    <!-- ============================================================================== -->
    <h1>How to create an Experiment template</h1>
    <p>
        You can create an Experiment Template either through <a [routerLink]="['/docs', 'rail-sdks']">RAIL Python SDK</a> or
        through <a [routerLink]="['/experiments', 'create']">web UI</a>.
    </p>

    <mat-tab-group>
        <mat-tab label="Python SDK">
            <markdown clipboard src="assets/docs/markdown/codes/create-experiment-template.md">
            </markdown>
        </mat-tab>
        <mat-tab label="Python SDK (alternative)">
            <markdown clipboard src="assets/docs/markdown/codes/create-experiment-template-v2.md">
            </markdown>
        </mat-tab>
        <mat-tab label="Web page">
            # Coming soon
        </mat-tab>
    </mat-tab-group>

    <h2>Properties of Experiment Template</h2>
    <markdown class="fixed-height-scrollable" src="assets/docs/markdown/et-properties.md">
    </markdown>

    <!-- ============================================================================== -->
    <h2>What happens when you create an Experiment template?</h2>
    When you create and Experiment Template, following happens:
    <ol>
        <li>
            An instance of an Experiment Template is created in the RAIL database. Now, it needs to be approved by the
            administrators of RAIL.
        </li>
        <li>
            Once the Experiment Template is approved, a Docker image representing the Experiment template is built. It
            is derived from the Runtime environment specified by the user. It has installed the dependencies defined in
            requirements.txt and contains the code specified by the author.
        </li>
        <li>
            After the image is built, it’s pushed to an image registry.
        </li>
    </ol>

    <!-- ============================================================================== -->
    <h1>How to write a RAIL-compatible Python script?</h1>
    <p>
        To create an Experiment Template, you need to write a Python script that is compatible with RAIL. The script
        should be able to run in a Docker container and should be able to use the datasets and models provided by RAIL
        (if any).
    </p>
    <p>
        There are no explicit technical restrictions on what Python (support for other languages is on the roadmap) code
        can be executed in with RAIL.
    </p>
    <p>
        In general:
    </p>
    <ul>
        <li>
            Your code must be contained in a single Python script.
        </li>
        <li>
            Your code must be compatible with the execution environment (Docker image) you selected and dependencies you
            declared.
        </li>
    </ul>

    <h2>Saving output files</h2>
    <p>
        Your code must save all the outputs to <code>“./output-temp”</code> directory. These <b>outputs will be
            available for 7 days</b>, after which they will be removed.
    </p>

    <h2>Saving output metrics</h2>
    <p>
        As many machine learning workflows compute some kind of metrics (both during training and inference), RAIL
        provides a simple mechanism to save and later browse metrics saved by your Experiment Template script.
    </p>
    <p>
        In order to save metrics, you need to save them as a dictionary to a json file named exactly
        <code>“metrics.json”</code>, where keys represent metric names and values metric values.
    </p>
    <markdown src="assets/docs/markdown/codes/et-metrics.md">
    </markdown>
    <p>
        Then, once you execute the Experiment (see later sections), you’ll have access to the metrics in Web UI and
        through Python SDK.
    </p>
    <img src="assets/docs/images/et-metrics.png" class="doc-illustration-figure" alt="Experiment Template: metrics">

    <h2>Accessing datasets and models (later defined in the Experiment)</h2>
    <p>
        The Python script has access to multiple environment variables that can be read for instance by using
        os.getenv("ENV_VAR"). First, there are reserved environment variables. These environment variables are filled in
        automatically by RAIL, based on what dataset(s) and model(s) the users select when they create an Experiment
        from and Experiment Template:
    </p>
    <ul>
        <li>
            <b>MODEL_NAMES</b>: Contains a list of model names (e.g. HuggingFace unique identifiers) that represent the
            models
            you want to use in your code.
        </li>
        <li>
            <b>DATASET_NAMES</b>: Contains a list of model names (e.g. HuggingFace unique identifiers) that represent
            the
            datasets you want to use in your code.
        </li>
        <li>
            <b>MODEL_IDS</b>: Contains a list of AIoD model IDs that represent the models you want to use in your code.
            These IDs can be used to read detailed information about the models from the AIoD or RAIL API.
        </li>
        <li>
            <b>DATASET_IDS</b>: Contains a list of AIoD dataset IDs that represent the datasets you want to use in your
            code. These IDs can be used to read detailed information about the datasets from the AIoD or RAIL API.
        </li>
    </ul>

    <h2>Accessing other environment variables</h2>
    <p>
        Then, the script will have access to environment variables defined by the author of the Experiment Template:
    </p>
    <ul>
        <li>envs_required</li>
        <li>envs_required</li>
    </ul>

    <p>
        <b>Important.</b> The administrators of RAIL reserve the right to not approve or disapprove Experiment Templates that may (even potentially) harm to the system, require more resources than the AIoD platform  is able to provide, and go against the law or policies of the platform.
    </p>

    <!-- ============================================================================== -->
    <h1>How can I use execute an Experiment Template</h1>
    <p>
        Experiment Template on its own is not executable. You need to create an <a [routerLink]="['/docs', 'main-concepts-experiment']">Experiment</a> based on a specific template to be able to execute it. The Experiment defines particular properties that are injected into the Template through Environment variables to make it executable. These include AI model, dataset (their name and AIoD ID) and environment variables supported by the template (they are defined by the author).
    </p>
    <p>
        See <a [routerLink]="['/docs', 'main-concepts-experiment']">Experiment</a> documentation for more information.
    </p>
   
</app-base-doc>